<div class="global">
    <div class="header">
        <h1>Shreya Kashi</h1>
        <div class="logos">
            <a href="https://github.com/ShreyaKashi"><img class="logo-ind git-logo" src="assets/GitHub-logo.svg"></a>
            <a href="https://www.linkedin.com/in/shreya-kashi/"><img class="logo-ind link-logo" src="assets/linkedin.svg"></a>
        </div>
    </div>
    
    <div class="intro-parent">
        <div class="intro-text">
            <p>Hello!</p>
            <p>I'm a master's student at Oregon State University studying Computer Science. 
            I'm working on computer vision applications in my research group, particularly on diverse dynamics prediction as a part of the <a href="https://www.darpa.mil/program/machine-common-sense">Machine Common Sense</a> initiative. 
            The objective is to model the uncertainty in the trajectories of scene elements so that the autonomous vehicle can reason about plausible collisions and their probabilities.</p>
            
            <p>DARPA's Machine Common Sense project piqued my interest in how machines reason, interpretable AI, and therefore in Artificial General Intelligence.  I'm particularly curious about drawing parallels between how different species learn and how machines learn (as explored in my <a href="https://docs.google.com/presentation/d/1txEygvsDJ79DT6c8Dl0_1aB89_Vdx3tTKzRw5fs3hGs/edit?usp=sharing">presentation</a> for the course 'Big Ideas in AI').</p>
            
            <p>You can find my resume <a href="assets/resume_shreya.pdf">here</a>.</p>    
        </div>

        <div class="profile-img">
            <img src="assets/profile1.jpg">
        </div>
        

    </div>

    <div class="projects-container">
        <h2>Projects</h2>
        <div class="projects-parent">
            <ol>
                <a href="https://drive.google.com/file/d/1TVO8jzVVdSNwo0qbw99axOchKSVOOsy8/view?usp=drive_link"><li>Stacked Hourglass Network for Efficient Multi-View Pose Estimation, Tracking,
                    and Forecasting</li></a>
                    <!-- <p>Key point detection</p> -->
                    <div class="tempo_imgs">
                        <img src="assets/qual_res1.png">
                        <img src="assets/qual_res2.png">
                    </div>
                    <p>Current state-of-the-art 3D pose estimation techniques use 2D CNNs to regress 2D pose in the projections of 3D volume. However, CNNs fail to capture relative joint label information which is required while predicting human poses. Stacked hourglass network has been used to address label correlation for pose estimation. In this project we replace 2D CNNs with SHG network and show that they offer accuracy boost in pose estimation.</p>
                    
                <a href="https://drive.google.com/file/d/12FBl5KFusFCCktN8WmDOWztym4IyOB2L/view?usp=drive_link"><li>Detecting Center Pivot Irrigation Systems in Satellite Images</li></a>
                <div class="watershed-img">
                    <img src="assets/watershed.png">
                </div>
                <p>Center pivot irrigation systems take up a lot of water. For water resource management and planning, it is essential to identify their numbers and the area irrigated by them. In this project we semantically segment these irrigation sytems using a U-net, detect individual instances using the watershed algorithm and regress the angle spanned by them.</p>
                
                <a href="https://github.com/ShreyaKashi/hti-cryo-em/tree/develop"><li>Identifying noisy images in the 2D Classification step of Cryo-EM</li></a>
                <p>3D density map construction in Cryo-EM requires clear, noise-free averaged 2D images. In this project I used a SVM and CNN to classify each image as clean or noisy based on the EMPAIR annotated dataset.</p>
                
                <a href="https://drive.google.com/file/d/1wWE4e98mETjsbbUCSMyAZAZVWPrenHHs/view"><li>Key Value Pair Extraction from Scanned Documents</li></a>
                <p>Using both layout information (RCNN) and textual association (BERT), we extract key-value pairs in PDF files. </p>
            </ol>
            

        </div>
    </div>
</div>

